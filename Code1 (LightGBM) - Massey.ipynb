{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c79b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from skimage.feature import canny\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6e24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDGE BASED SEGMENTATION\n",
    "def preprocess1(image):\n",
    "  # resizing\n",
    "  image = cv2.resize(image,(96,96))\n",
    "  # gray scaling\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  # log transformation\n",
    "  c=0\n",
    "  if np.max(image) == 0:\n",
    "        c=0\n",
    "  else:\n",
    "        c = 255 / np.log(1 + np.max(image)) \n",
    "  log_image = c * (np.log(image + 1)) \n",
    "  log_image = np.array(log_image, dtype = np.uint8)  \n",
    "  # canny edge detection\n",
    "  image = canny(log_image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2545675",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = 'massey_dataset'\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for img in os.listdir(rootdir):\n",
    "    label=img.split('_')[1]\n",
    "    img = os.path.join(rootdir, img)\n",
    "    image = cv2.imread(img)\n",
    "    image = preprocess1(image)\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "    \n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c259aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7f997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) \n",
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=80)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67e9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 5}\n",
      "Best score:  0.8732954545454545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89        25\n",
      "           1       0.84      0.95      0.89        22\n",
      "           2       0.95      1.00      0.98        20\n",
      "           3       1.00      0.96      0.98        23\n",
      "           4       0.89      0.81      0.85        21\n",
      "           5       0.95      0.90      0.93        21\n",
      "           6       0.80      0.95      0.87        21\n",
      "           7       0.76      0.89      0.82        18\n",
      "           8       0.88      0.79      0.83        19\n",
      "           9       0.94      0.94      0.94        17\n",
      "          10       0.76      0.93      0.84        14\n",
      "          11       0.92      0.85      0.88        26\n",
      "          12       0.94      0.88      0.91        17\n",
      "          13       0.71      0.85      0.77        20\n",
      "          14       1.00      0.95      0.98        21\n",
      "          15       0.87      0.81      0.84        16\n",
      "          16       1.00      1.00      1.00        22\n",
      "          17       1.00      1.00      1.00        22\n",
      "          18       0.96      0.92      0.94        25\n",
      "          19       0.88      0.96      0.92        23\n",
      "          20       1.00      0.72      0.84        18\n",
      "          21       0.86      1.00      0.92        18\n",
      "          22       0.86      0.79      0.83        24\n",
      "          23       0.87      0.81      0.84        32\n",
      "          24       0.89      0.81      0.85        21\n",
      "          25       0.95      1.00      0.97        18\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       1.00      0.88      0.93        24\n",
      "          28       0.63      0.71      0.67        24\n",
      "          29       0.67      0.75      0.71        16\n",
      "          30       0.81      0.85      0.83        20\n",
      "          31       0.88      0.78      0.82        18\n",
      "          32       0.88      0.79      0.83        19\n",
      "          33       0.95      0.90      0.92        20\n",
      "          34       1.00      0.96      0.98        26\n",
      "          35       0.95      0.86      0.90        22\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "Accuracy: 88.74%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0291867",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) \n",
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=100)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e14a837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 5}\n",
      "Best score:  0.8693181818181819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87        25\n",
      "           1       0.95      0.95      0.95        22\n",
      "           2       0.86      0.90      0.88        20\n",
      "           3       1.00      0.91      0.95        23\n",
      "           4       0.84      0.76      0.80        21\n",
      "           5       0.90      0.90      0.90        21\n",
      "           6       0.88      1.00      0.93        21\n",
      "           7       0.80      0.89      0.84        18\n",
      "           8       0.88      0.79      0.83        19\n",
      "           9       0.94      0.88      0.91        17\n",
      "          10       0.82      1.00      0.90        14\n",
      "          11       0.96      0.88      0.92        26\n",
      "          12       0.94      0.94      0.94        17\n",
      "          13       0.74      0.70      0.72        20\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       0.88      0.88      0.88        16\n",
      "          16       1.00      0.95      0.98        22\n",
      "          17       0.96      1.00      0.98        22\n",
      "          18       0.89      0.96      0.92        25\n",
      "          19       0.88      1.00      0.94        23\n",
      "          20       0.88      0.83      0.86        18\n",
      "          21       0.90      1.00      0.95        18\n",
      "          22       0.90      0.79      0.84        24\n",
      "          23       0.89      0.78      0.83        32\n",
      "          24       0.85      0.81      0.83        21\n",
      "          25       0.90      1.00      0.95        18\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       1.00      0.92      0.96        24\n",
      "          28       0.73      0.67      0.70        24\n",
      "          29       0.60      0.75      0.67        16\n",
      "          30       0.78      0.90      0.84        20\n",
      "          31       0.88      0.78      0.82        18\n",
      "          32       0.89      0.89      0.89        19\n",
      "          33       0.95      0.90      0.92        20\n",
      "          34       0.96      0.96      0.96        26\n",
      "          35       0.95      0.86      0.90        22\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "Accuracy: 89.01%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d31601",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) \n",
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=150)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9656ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 5}\n",
      "Best score:  0.8732954545454545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87        25\n",
      "           1       0.95      0.95      0.95        22\n",
      "           2       0.83      0.95      0.88        20\n",
      "           3       1.00      0.96      0.98        23\n",
      "           4       0.90      0.86      0.88        21\n",
      "           5       0.90      0.90      0.90        21\n",
      "           6       0.83      0.90      0.86        21\n",
      "           7       0.79      0.83      0.81        18\n",
      "           8       0.71      0.79      0.75        19\n",
      "           9       0.83      0.88      0.86        17\n",
      "          10       0.88      1.00      0.93        14\n",
      "          11       0.92      0.88      0.90        26\n",
      "          12       0.94      0.88      0.91        17\n",
      "          13       0.67      0.80      0.73        20\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       0.93      0.81      0.87        16\n",
      "          16       1.00      0.95      0.98        22\n",
      "          17       1.00      1.00      1.00        22\n",
      "          18       0.96      0.96      0.96        25\n",
      "          19       0.85      0.96      0.90        23\n",
      "          20       1.00      0.78      0.88        18\n",
      "          21       0.90      1.00      0.95        18\n",
      "          22       0.83      0.83      0.83        24\n",
      "          23       0.93      0.84      0.89        32\n",
      "          24       0.79      0.90      0.84        21\n",
      "          25       0.95      1.00      0.97        18\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       1.00      0.83      0.91        24\n",
      "          28       0.74      0.71      0.72        24\n",
      "          29       0.63      0.75      0.69        16\n",
      "          30       0.77      0.85      0.81        20\n",
      "          31       0.93      0.72      0.81        18\n",
      "          32       0.94      0.79      0.86        19\n",
      "          33       0.90      0.90      0.90        20\n",
      "          34       1.00      0.96      0.98        26\n",
      "          35       0.86      0.86      0.86        22\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.88       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "Accuracy: 88.61%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca58d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) \n",
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=200)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28b8bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 5}\n",
      "Best score:  0.8744318181818181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        25\n",
      "           1       0.95      0.95      0.95        22\n",
      "           2       0.78      0.90      0.84        20\n",
      "           3       1.00      0.96      0.98        23\n",
      "           4       0.90      0.86      0.88        21\n",
      "           5       0.95      0.90      0.93        21\n",
      "           6       0.90      0.86      0.88        21\n",
      "           7       0.83      0.83      0.83        18\n",
      "           8       0.80      0.84      0.82        19\n",
      "           9       0.89      0.94      0.91        17\n",
      "          10       0.78      1.00      0.88        14\n",
      "          11       0.92      0.88      0.90        26\n",
      "          12       0.94      0.88      0.91        17\n",
      "          13       0.76      0.80      0.78        20\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       0.87      0.81      0.84        16\n",
      "          16       1.00      0.95      0.98        22\n",
      "          17       1.00      1.00      1.00        22\n",
      "          18       0.92      0.96      0.94        25\n",
      "          19       0.88      0.96      0.92        23\n",
      "          20       0.94      0.89      0.91        18\n",
      "          21       0.90      1.00      0.95        18\n",
      "          22       0.91      0.83      0.87        24\n",
      "          23       0.92      0.75      0.83        32\n",
      "          24       0.79      0.90      0.84        21\n",
      "          25       0.90      1.00      0.95        18\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       1.00      0.92      0.96        24\n",
      "          28       0.74      0.71      0.72        24\n",
      "          29       0.72      0.81      0.76        16\n",
      "          30       0.77      0.85      0.81        20\n",
      "          31       0.87      0.72      0.79        18\n",
      "          32       0.89      0.89      0.89        19\n",
      "          33       0.86      0.90      0.88        20\n",
      "          34       1.00      1.00      1.00        26\n",
      "          35       0.86      0.82      0.84        22\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.90      0.89      0.89       755\n",
      "\n",
      "Accuracy: 89.27%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63f0ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) \n",
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=120)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d218fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 5}\n",
      "Best score:  0.8732954545454545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84        25\n",
      "           1       1.00      0.95      0.98        22\n",
      "           2       0.90      0.90      0.90        20\n",
      "           3       0.95      0.91      0.93        23\n",
      "           4       0.81      0.81      0.81        21\n",
      "           5       0.90      0.90      0.90        21\n",
      "           6       0.95      0.90      0.93        21\n",
      "           7       0.79      0.83      0.81        18\n",
      "           8       0.88      0.79      0.83        19\n",
      "           9       0.89      0.94      0.91        17\n",
      "          10       0.93      0.93      0.93        14\n",
      "          11       0.92      0.88      0.90        26\n",
      "          12       0.89      0.94      0.91        17\n",
      "          13       0.68      0.85      0.76        20\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       0.86      0.75      0.80        16\n",
      "          16       1.00      0.95      0.98        22\n",
      "          17       1.00      1.00      1.00        22\n",
      "          18       0.92      0.96      0.94        25\n",
      "          19       0.85      1.00      0.92        23\n",
      "          20       0.88      0.83      0.86        18\n",
      "          21       0.86      1.00      0.92        18\n",
      "          22       1.00      0.79      0.88        24\n",
      "          23       0.87      0.81      0.84        32\n",
      "          24       0.82      0.86      0.84        21\n",
      "          25       0.95      1.00      0.97        18\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       1.00      0.88      0.93        24\n",
      "          28       0.78      0.75      0.77        24\n",
      "          29       0.72      0.81      0.76        16\n",
      "          30       0.83      0.95      0.88        20\n",
      "          31       0.87      0.72      0.79        18\n",
      "          32       0.90      0.95      0.92        19\n",
      "          33       0.95      0.90      0.92        20\n",
      "          34       0.96      0.96      0.96        26\n",
      "          35       0.83      0.86      0.84        22\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.90      0.89      0.89       755\n",
      "\n",
      "Accuracy: 89.27%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeed600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) \n",
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=110)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70abc670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 5}\n",
      "Best score:  0.8761363636363637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        25\n",
      "           1       0.95      0.95      0.95        22\n",
      "           2       0.79      0.95      0.86        20\n",
      "           3       1.00      0.96      0.98        23\n",
      "           4       0.89      0.81      0.85        21\n",
      "           5       0.90      0.90      0.90        21\n",
      "           6       0.71      0.81      0.76        21\n",
      "           7       0.82      0.78      0.80        18\n",
      "           8       0.84      0.84      0.84        19\n",
      "           9       0.84      0.94      0.89        17\n",
      "          10       1.00      0.93      0.96        14\n",
      "          11       0.92      0.88      0.90        26\n",
      "          12       0.84      0.94      0.89        17\n",
      "          13       0.71      0.85      0.77        20\n",
      "          14       1.00      1.00      1.00        21\n",
      "          15       0.94      0.94      0.94        16\n",
      "          16       0.95      0.91      0.93        22\n",
      "          17       1.00      1.00      1.00        22\n",
      "          18       0.92      0.96      0.94        25\n",
      "          19       0.85      0.96      0.90        23\n",
      "          20       1.00      0.78      0.88        18\n",
      "          21       0.90      1.00      0.95        18\n",
      "          22       0.86      0.79      0.83        24\n",
      "          23       0.86      0.75      0.80        32\n",
      "          24       0.79      0.90      0.84        21\n",
      "          25       0.90      1.00      0.95        18\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       0.95      0.83      0.89        24\n",
      "          28       0.68      0.71      0.69        24\n",
      "          29       0.65      0.81      0.72        16\n",
      "          30       0.71      0.85      0.77        20\n",
      "          31       1.00      0.67      0.80        18\n",
      "          32       0.84      0.84      0.84        19\n",
      "          33       0.90      0.90      0.90        20\n",
      "          34       1.00      0.92      0.96        26\n",
      "          35       0.90      0.82      0.86        22\n",
      "\n",
      "    accuracy                           0.88       755\n",
      "   macro avg       0.88      0.88      0.88       755\n",
      "weighted avg       0.89      0.88      0.88       755\n",
      "\n",
      "Accuracy: 87.81%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5b95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) \n",
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=300)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e4ab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 5}\n",
      "Best score:  0.8659090909090909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        25\n",
      "           1       0.95      0.95      0.95        22\n",
      "           2       0.81      0.85      0.83        20\n",
      "           3       0.95      0.91      0.93        23\n",
      "           4       0.89      0.76      0.82        21\n",
      "           5       0.90      0.90      0.90        21\n",
      "           6       0.78      0.86      0.82        21\n",
      "           7       0.83      0.83      0.83        18\n",
      "           8       0.76      0.84      0.80        19\n",
      "           9       0.89      0.94      0.91        17\n",
      "          10       0.88      1.00      0.93        14\n",
      "          11       0.96      0.92      0.94        26\n",
      "          12       0.94      0.88      0.91        17\n",
      "          13       0.75      0.90      0.82        20\n",
      "          14       0.95      0.95      0.95        21\n",
      "          15       0.93      0.88      0.90        16\n",
      "          16       1.00      0.95      0.98        22\n",
      "          17       1.00      1.00      1.00        22\n",
      "          18       0.92      0.96      0.94        25\n",
      "          19       0.85      0.96      0.90        23\n",
      "          20       0.88      0.78      0.82        18\n",
      "          21       0.86      1.00      0.92        18\n",
      "          22       0.90      0.79      0.84        24\n",
      "          23       0.92      0.75      0.83        32\n",
      "          24       0.91      0.95      0.93        21\n",
      "          25       0.94      0.94      0.94        18\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       0.95      0.88      0.91        24\n",
      "          28       0.75      0.75      0.75        24\n",
      "          29       0.71      0.75      0.73        16\n",
      "          30       0.71      0.85      0.77        20\n",
      "          31       0.86      0.67      0.75        18\n",
      "          32       0.89      0.84      0.86        19\n",
      "          33       0.90      0.90      0.90        20\n",
      "          34       0.96      1.00      0.98        26\n",
      "          35       0.90      0.86      0.88        22\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.88       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "Accuracy: 88.74%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
