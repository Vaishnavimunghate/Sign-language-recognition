{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d4336ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from skimage.feature import canny\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62dec947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDGE BASED SEGMENTATION\n",
    "def preprocess1(image):\n",
    "  # resizing\n",
    "  image = cv2.resize(image,(96,96))\n",
    "  # gray scaling\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#   # log transformation\n",
    "#   c=0\n",
    "#   if np.max(image) == 0:\n",
    "#         c=0\n",
    "#   else:\n",
    "#         c = 255 / np.log(1 + np.max(image)) \n",
    "#   log_image = c * (np.log(image + 1)) \n",
    "#   log_image = np.array(log_image, dtype = np.uint8)  \n",
    "#   # canny edge detection\n",
    "#   image = canny(log_image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959e7dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = 'asl_alphabet/asl_alphabet_train/asl_alphabet_train'\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for folder in os.listdir(rootdir):\n",
    "    classes = os.path.join(rootdir,folder)\n",
    "    label = folder\n",
    "    for file in os.listdir(classes):\n",
    "        img = os.path.join(classes, file)\n",
    "        image = cv2.imread(img)\n",
    "        image = preprocess1(image)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b052cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a4f22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b827538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 200\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d14c050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.81      0.80       883\n",
      "         1.0       0.76      0.80      0.78       966\n",
      "         2.0       0.84      0.85      0.85       972\n",
      "         3.0       0.86      0.83      0.85       892\n",
      "         4.0       0.75      0.71      0.73       901\n",
      "         5.0       0.90      0.90      0.90       847\n",
      "         6.0       0.81      0.83      0.82       907\n",
      "         7.0       0.81      0.88      0.84       851\n",
      "         8.0       0.78      0.77      0.77       898\n",
      "         9.0       0.76      0.82      0.79       881\n",
      "        10.0       0.85      0.82      0.84       934\n",
      "        11.0       0.85      0.89      0.87       904\n",
      "        12.0       0.64      0.64      0.64       853\n",
      "        13.0       0.68      0.60      0.64       900\n",
      "        14.0       0.71      0.72      0.72       878\n",
      "        15.0       0.71      0.77      0.74       866\n",
      "        16.0       0.75      0.79      0.77       873\n",
      "        17.0       0.69      0.73      0.71       870\n",
      "        18.0       0.66      0.66      0.66       921\n",
      "        19.0       0.76      0.75      0.75       886\n",
      "        20.0       0.68      0.65      0.67       926\n",
      "        21.0       0.71      0.68      0.70       875\n",
      "        22.0       0.75      0.76      0.75       925\n",
      "        23.0       0.61      0.56      0.59       895\n",
      "        24.0       0.73      0.72      0.73       897\n",
      "        25.0       0.66      0.62      0.64       881\n",
      "        26.0       0.69      0.64      0.66       947\n",
      "        27.0       0.97      1.00      0.98       951\n",
      "        28.0       0.62      0.61      0.62       920\n",
      "\n",
      "    accuracy                           0.75     26100\n",
      "   macro avg       0.75      0.75      0.75     26100\n",
      "weighted avg       0.75      0.75      0.75     26100\n",
      "\n",
      "Accuracy: 75.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4156366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 100 words\n",
    "# accuracy with log transformation - 55% \n",
    "# accuracy w/o = 59.08%\n",
    "\n",
    "# with 200 words\n",
    "# accuracy w/o = 75.25%\n",
    "\n",
    "# with 300 words\n",
    "# accuracy w/o = 82.35%\n",
    "\n",
    "# with 500 words\n",
    "# accuracy w/o = 89.23%\n",
    "\n",
    "# with 700 words\n",
    "# accuracy w/o = 92.69%\n",
    "\n",
    "# with 1000 words\n",
    "# accuracy w/o = 94.77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896f3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 300\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f786b2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85       883\n",
      "         1.0       0.85      0.87      0.86       966\n",
      "         2.0       0.89      0.90      0.89       972\n",
      "         3.0       0.91      0.89      0.90       892\n",
      "         4.0       0.82      0.79      0.80       901\n",
      "         5.0       0.94      0.96      0.95       847\n",
      "         6.0       0.89      0.88      0.88       907\n",
      "         7.0       0.89      0.92      0.91       851\n",
      "         8.0       0.85      0.83      0.84       898\n",
      "         9.0       0.85      0.88      0.87       881\n",
      "        10.0       0.90      0.89      0.89       934\n",
      "        11.0       0.91      0.93      0.92       904\n",
      "        12.0       0.70      0.73      0.72       853\n",
      "        13.0       0.77      0.72      0.74       900\n",
      "        14.0       0.79      0.83      0.81       878\n",
      "        15.0       0.80      0.80      0.80       866\n",
      "        16.0       0.82      0.83      0.83       873\n",
      "        17.0       0.76      0.75      0.75       870\n",
      "        18.0       0.75      0.78      0.77       921\n",
      "        19.0       0.83      0.83      0.83       886\n",
      "        20.0       0.77      0.75      0.76       926\n",
      "        21.0       0.77      0.78      0.77       875\n",
      "        22.0       0.84      0.82      0.83       925\n",
      "        23.0       0.73      0.71      0.72       895\n",
      "        24.0       0.78      0.79      0.78       897\n",
      "        25.0       0.75      0.72      0.73       881\n",
      "        26.0       0.77      0.75      0.76       947\n",
      "        27.0       0.96      1.00      0.98       951\n",
      "        28.0       0.73      0.71      0.72       920\n",
      "\n",
      "    accuracy                           0.82     26100\n",
      "   macro avg       0.82      0.82      0.82     26100\n",
      "weighted avg       0.82      0.82      0.82     26100\n",
      "\n",
      "Accuracy: 82.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21593b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 500\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e55d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.92      0.91       883\n",
      "         1.0       0.91      0.91      0.91       966\n",
      "         2.0       0.93      0.94      0.94       972\n",
      "         3.0       0.94      0.94      0.94       892\n",
      "         4.0       0.91      0.89      0.90       901\n",
      "         5.0       0.96      0.98      0.97       847\n",
      "         6.0       0.93      0.93      0.93       907\n",
      "         7.0       0.94      0.96      0.95       851\n",
      "         8.0       0.91      0.92      0.91       898\n",
      "         9.0       0.90      0.93      0.92       881\n",
      "        10.0       0.94      0.91      0.93       934\n",
      "        11.0       0.95      0.96      0.95       904\n",
      "        12.0       0.81      0.83      0.82       853\n",
      "        13.0       0.83      0.82      0.82       900\n",
      "        14.0       0.89      0.89      0.89       878\n",
      "        15.0       0.90      0.90      0.90       866\n",
      "        16.0       0.89      0.88      0.88       873\n",
      "        17.0       0.86      0.84      0.85       870\n",
      "        18.0       0.86      0.83      0.84       921\n",
      "        19.0       0.90      0.89      0.89       886\n",
      "        20.0       0.84      0.85      0.85       926\n",
      "        21.0       0.86      0.85      0.86       875\n",
      "        22.0       0.90      0.89      0.89       925\n",
      "        23.0       0.81      0.82      0.82       895\n",
      "        24.0       0.88      0.86      0.87       897\n",
      "        25.0       0.85      0.85      0.85       881\n",
      "        26.0       0.84      0.83      0.84       947\n",
      "        27.0       0.97      1.00      0.98       951\n",
      "        28.0       0.85      0.85      0.85       920\n",
      "\n",
      "    accuracy                           0.89     26100\n",
      "   macro avg       0.89      0.89      0.89     26100\n",
      "weighted avg       0.89      0.89      0.89     26100\n",
      "\n",
      "Accuracy: 89.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d360a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 700\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d42280d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94       883\n",
      "         1.0       0.93      0.92      0.93       966\n",
      "         2.0       0.97      0.96      0.97       972\n",
      "         3.0       0.96      0.95      0.96       892\n",
      "         4.0       0.92      0.93      0.92       901\n",
      "         5.0       0.98      0.99      0.98       847\n",
      "         6.0       0.96      0.97      0.97       907\n",
      "         7.0       0.97      0.97      0.97       851\n",
      "         8.0       0.95      0.92      0.93       898\n",
      "         9.0       0.96      0.95      0.95       881\n",
      "        10.0       0.96      0.95      0.95       934\n",
      "        11.0       0.96      0.97      0.97       904\n",
      "        12.0       0.89      0.87      0.88       853\n",
      "        13.0       0.87      0.87      0.87       900\n",
      "        14.0       0.92      0.94      0.93       878\n",
      "        15.0       0.93      0.94      0.94       866\n",
      "        16.0       0.94      0.94      0.94       873\n",
      "        17.0       0.89      0.88      0.88       870\n",
      "        18.0       0.88      0.88      0.88       921\n",
      "        19.0       0.94      0.94      0.94       886\n",
      "        20.0       0.90      0.90      0.90       926\n",
      "        21.0       0.89      0.88      0.89       875\n",
      "        22.0       0.93      0.92      0.92       925\n",
      "        23.0       0.88      0.89      0.89       895\n",
      "        24.0       0.93      0.92      0.93       897\n",
      "        25.0       0.91      0.90      0.91       881\n",
      "        26.0       0.90      0.90      0.90       947\n",
      "        27.0       0.95      1.00      0.98       951\n",
      "        28.0       0.88      0.88      0.88       920\n",
      "\n",
      "    accuracy                           0.93     26100\n",
      "   macro avg       0.93      0.93      0.93     26100\n",
      "weighted avg       0.93      0.93      0.93     26100\n",
      "\n",
      "Accuracy: 92.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a7556d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 1000\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a1bb748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       883\n",
      "         1.0       0.94      0.94      0.94       966\n",
      "         2.0       0.97      0.97      0.97       972\n",
      "         3.0       0.98      0.96      0.97       892\n",
      "         4.0       0.95      0.95      0.95       901\n",
      "         5.0       0.97      0.99      0.98       847\n",
      "         6.0       0.96      0.98      0.97       907\n",
      "         7.0       0.97      0.98      0.97       851\n",
      "         8.0       0.96      0.95      0.96       898\n",
      "         9.0       0.97      0.97      0.97       881\n",
      "        10.0       0.96      0.96      0.96       934\n",
      "        11.0       0.97      0.99      0.98       904\n",
      "        12.0       0.91      0.90      0.91       853\n",
      "        13.0       0.92      0.91      0.91       900\n",
      "        14.0       0.93      0.94      0.94       878\n",
      "        15.0       0.95      0.95      0.95       866\n",
      "        16.0       0.95      0.96      0.96       873\n",
      "        17.0       0.93      0.93      0.93       870\n",
      "        18.0       0.92      0.91      0.92       921\n",
      "        19.0       0.95      0.95      0.95       886\n",
      "        20.0       0.93      0.93      0.93       926\n",
      "        21.0       0.93      0.93      0.93       875\n",
      "        22.0       0.95      0.95      0.95       925\n",
      "        23.0       0.91      0.92      0.92       895\n",
      "        24.0       0.95      0.94      0.95       897\n",
      "        25.0       0.94      0.94      0.94       881\n",
      "        26.0       0.94      0.92      0.93       947\n",
      "        27.0       0.98      1.00      0.99       951\n",
      "        28.0       0.93      0.92      0.92       920\n",
      "\n",
      "    accuracy                           0.95     26100\n",
      "   macro avg       0.95      0.95      0.95     26100\n",
      "weighted avg       0.95      0.95      0.95     26100\n",
      "\n",
      "Accuracy: 94.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e766d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 1200\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b96ab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       883\n",
      "         1.0       0.96      0.95      0.96       966\n",
      "         2.0       0.98      0.97      0.97       972\n",
      "         3.0       0.98      0.97      0.98       892\n",
      "         4.0       0.96      0.96      0.96       901\n",
      "         5.0       0.97      0.99      0.98       847\n",
      "         6.0       0.97      0.98      0.97       907\n",
      "         7.0       0.97      0.98      0.97       851\n",
      "         8.0       0.97      0.96      0.97       898\n",
      "         9.0       0.98      0.96      0.97       881\n",
      "        10.0       0.97      0.97      0.97       934\n",
      "        11.0       0.98      0.99      0.99       904\n",
      "        12.0       0.91      0.94      0.92       853\n",
      "        13.0       0.92      0.91      0.92       900\n",
      "        14.0       0.94      0.95      0.95       878\n",
      "        15.0       0.95      0.96      0.96       866\n",
      "        16.0       0.96      0.97      0.96       873\n",
      "        17.0       0.94      0.94      0.94       870\n",
      "        18.0       0.93      0.93      0.93       921\n",
      "        19.0       0.97      0.97      0.97       886\n",
      "        20.0       0.93      0.93      0.93       926\n",
      "        21.0       0.91      0.92      0.92       875\n",
      "        22.0       0.96      0.96      0.96       925\n",
      "        23.0       0.93      0.93      0.93       895\n",
      "        24.0       0.96      0.95      0.96       897\n",
      "        25.0       0.96      0.96      0.96       881\n",
      "        26.0       0.96      0.93      0.94       947\n",
      "        27.0       0.97      1.00      0.99       951\n",
      "        28.0       0.95      0.93      0.94       920\n",
      "\n",
      "    accuracy                           0.96     26100\n",
      "   macro avg       0.96      0.96      0.96     26100\n",
      "weighted avg       0.96      0.96      0.96     26100\n",
      "\n",
      "Accuracy: 95.62%\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0cecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 1400\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dab9a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       886\n",
      "         1.0       0.95      0.95      0.95       881\n",
      "         2.0       0.98      0.98      0.98       897\n",
      "         3.0       0.98      0.98      0.98       898\n",
      "         4.0       0.97      0.95      0.96       951\n",
      "         5.0       0.99      0.99      0.99       926\n",
      "         6.0       0.98      0.98      0.98       895\n",
      "         7.0       0.97      0.98      0.97       851\n",
      "         8.0       0.96      0.97      0.97       883\n",
      "         9.0       0.98      0.98      0.98       904\n",
      "        10.0       0.96      0.97      0.97       907\n",
      "        11.0       0.99      0.99      0.99       847\n",
      "        12.0       0.94      0.94      0.94       873\n",
      "        13.0       0.93      0.93      0.93       892\n",
      "        14.0       0.96      0.96      0.96       878\n",
      "        15.0       0.97      0.97      0.97       925\n",
      "        16.0       0.97      0.97      0.97       866\n",
      "        17.0       0.94      0.96      0.95       921\n",
      "        18.0       0.94      0.94      0.94       853\n",
      "        19.0       0.98      0.97      0.98       901\n",
      "        20.0       0.95      0.93      0.94       947\n",
      "        21.0       0.95      0.92      0.94       966\n",
      "        22.0       0.94      0.96      0.95       881\n",
      "        23.0       0.94      0.95      0.95       875\n",
      "        24.0       0.97      0.97      0.97       900\n",
      "        25.0       0.96      0.98      0.97       870\n",
      "        26.0       0.94      0.93      0.94       972\n",
      "        27.0       0.96      1.00      0.98       934\n",
      "        28.0       0.96      0.95      0.95       920\n",
      "\n",
      "    accuracy                           0.96     26100\n",
      "   macro avg       0.96      0.96      0.96     26100\n",
      "weighted avg       0.96      0.96      0.96     26100\n",
      "\n",
      "Accuracy: 96.18%\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63fceb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 1600\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a19a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       886\n",
      "         1.0       0.95      0.96      0.96       881\n",
      "         2.0       0.98      0.98      0.98       897\n",
      "         3.0       0.99      0.99      0.99       898\n",
      "         4.0       0.97      0.96      0.97       951\n",
      "         5.0       0.99      0.99      0.99       926\n",
      "         6.0       0.98      0.99      0.98       895\n",
      "         7.0       0.98      0.98      0.98       851\n",
      "         8.0       0.98      0.98      0.98       883\n",
      "         9.0       0.99      0.99      0.99       904\n",
      "        10.0       0.97      0.98      0.98       907\n",
      "        11.0       0.98      0.99      0.99       847\n",
      "        12.0       0.94      0.93      0.93       873\n",
      "        13.0       0.94      0.93      0.94       892\n",
      "        14.0       0.97      0.97      0.97       878\n",
      "        15.0       0.98      0.97      0.98       925\n",
      "        16.0       0.97      0.98      0.97       866\n",
      "        17.0       0.95      0.95      0.95       921\n",
      "        18.0       0.93      0.95      0.94       853\n",
      "        19.0       0.98      0.98      0.98       901\n",
      "        20.0       0.96      0.94      0.95       947\n",
      "        21.0       0.96      0.94      0.95       966\n",
      "        22.0       0.97      0.97      0.97       881\n",
      "        23.0       0.95      0.95      0.95       875\n",
      "        24.0       0.97      0.98      0.97       900\n",
      "        25.0       0.97      0.98      0.97       870\n",
      "        26.0       0.95      0.93      0.94       972\n",
      "        27.0       0.96      1.00      0.98       934\n",
      "        28.0       0.97      0.95      0.96       920\n",
      "\n",
      "    accuracy                           0.97     26100\n",
      "   macro avg       0.97      0.97      0.97     26100\n",
      "weighted avg       0.97      0.97      0.97     26100\n",
      "\n",
      "Accuracy: 96.78%\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0bd66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
