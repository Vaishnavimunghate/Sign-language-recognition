{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cec452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from skimage.feature import canny\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1616b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDGE BASED SEGMENTATION\n",
    "def preprocess1(image):\n",
    "  # resizing\n",
    "  image = cv2.resize(image,(96,96))\n",
    "  # gray scaling\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c529b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = 'massey_dataset'\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for img in os.listdir(rootdir):\n",
    "    label=img.split('_')[1]\n",
    "    img = os.path.join(rootdir, img)\n",
    "    image = cv2.imread(img)\n",
    "    image = preprocess1(image)\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "    \n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f74d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025b24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 200\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c5243f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.56      0.55        25\n",
      "         1.0       0.59      0.45      0.51        22\n",
      "         2.0       0.64      0.80      0.71        20\n",
      "         3.0       0.77      0.87      0.82        23\n",
      "         4.0       0.68      0.81      0.74        21\n",
      "         5.0       0.95      0.90      0.93        21\n",
      "         6.0       0.64      0.67      0.65        21\n",
      "         7.0       0.78      0.78      0.78        18\n",
      "         8.0       0.67      0.74      0.70        19\n",
      "         9.0       0.68      0.88      0.77        17\n",
      "        10.0       0.67      0.86      0.75        14\n",
      "        11.0       0.95      0.77      0.85        26\n",
      "        12.0       0.86      0.71      0.77        17\n",
      "        13.0       0.57      0.60      0.59        20\n",
      "        14.0       0.58      0.71      0.64        21\n",
      "        15.0       0.78      0.88      0.82        16\n",
      "        16.0       0.76      0.73      0.74        22\n",
      "        17.0       0.89      0.77      0.83        22\n",
      "        18.0       0.75      0.84      0.79        25\n",
      "        19.0       0.85      0.96      0.90        23\n",
      "        20.0       0.86      0.67      0.75        18\n",
      "        21.0       0.79      0.83      0.81        18\n",
      "        22.0       0.67      0.67      0.67        24\n",
      "        23.0       0.64      0.50      0.56        32\n",
      "        24.0       0.58      0.67      0.62        21\n",
      "        25.0       0.94      0.83      0.88        18\n",
      "        26.0       0.95      0.91      0.93        22\n",
      "        27.0       0.67      0.67      0.67        24\n",
      "        28.0       0.55      0.71      0.62        24\n",
      "        29.0       0.60      0.75      0.67        16\n",
      "        30.0       0.77      0.50      0.61        20\n",
      "        31.0       0.40      0.22      0.29        18\n",
      "        32.0       0.61      0.58      0.59        19\n",
      "        33.0       0.78      0.90      0.84        20\n",
      "        34.0       0.90      0.73      0.81        26\n",
      "        35.0       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.72       755\n",
      "   macro avg       0.72      0.72      0.72       755\n",
      "weighted avg       0.72      0.72      0.71       755\n",
      "\n",
      "Accuracy: 71.66%\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ddb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 500\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b600b814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.80      0.77        25\n",
      "         1.0       0.78      0.82      0.80        22\n",
      "         2.0       0.71      0.85      0.77        20\n",
      "         3.0       0.92      0.96      0.94        23\n",
      "         4.0       0.74      0.95      0.83        21\n",
      "         5.0       0.95      0.95      0.95        21\n",
      "         6.0       0.67      0.57      0.62        21\n",
      "         7.0       0.94      0.83      0.88        18\n",
      "         8.0       0.89      0.89      0.89        19\n",
      "         9.0       1.00      0.88      0.94        17\n",
      "        10.0       0.88      1.00      0.93        14\n",
      "        11.0       1.00      0.96      0.98        26\n",
      "        12.0       0.93      0.82      0.87        17\n",
      "        13.0       0.71      0.75      0.73        20\n",
      "        14.0       0.90      0.90      0.90        21\n",
      "        15.0       0.94      1.00      0.97        16\n",
      "        16.0       1.00      0.86      0.93        22\n",
      "        17.0       0.91      0.91      0.91        22\n",
      "        18.0       0.91      0.84      0.87        25\n",
      "        19.0       0.96      0.96      0.96        23\n",
      "        20.0       0.84      0.89      0.86        18\n",
      "        21.0       1.00      0.89      0.94        18\n",
      "        22.0       0.85      0.96      0.90        24\n",
      "        23.0       0.85      0.69      0.76        32\n",
      "        24.0       0.78      0.86      0.82        21\n",
      "        25.0       0.89      0.94      0.92        18\n",
      "        26.0       1.00      1.00      1.00        22\n",
      "        27.0       1.00      0.83      0.91        24\n",
      "        28.0       0.83      0.83      0.83        24\n",
      "        29.0       0.83      0.94      0.88        16\n",
      "        30.0       1.00      0.95      0.97        20\n",
      "        31.0       0.86      0.67      0.75        18\n",
      "        32.0       0.60      0.79      0.68        19\n",
      "        33.0       0.90      0.95      0.93        20\n",
      "        34.0       0.96      0.92      0.94        26\n",
      "        35.0       0.86      0.82      0.84        22\n",
      "\n",
      "    accuracy                           0.87       755\n",
      "   macro avg       0.88      0.87      0.87       755\n",
      "weighted avg       0.88      0.87      0.87       755\n",
      "\n",
      "Accuracy: 87.02%\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df3fc15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 1000\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3615071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.80      0.75        25\n",
      "         1.0       0.84      0.73      0.78        22\n",
      "         2.0       0.85      0.85      0.85        20\n",
      "         3.0       0.96      1.00      0.98        23\n",
      "         4.0       0.86      0.90      0.88        21\n",
      "         5.0       0.84      1.00      0.91        21\n",
      "         6.0       0.82      0.67      0.74        21\n",
      "         7.0       0.90      1.00      0.95        18\n",
      "         8.0       0.85      0.89      0.87        19\n",
      "         9.0       1.00      0.94      0.97        17\n",
      "        10.0       0.93      1.00      0.97        14\n",
      "        11.0       1.00      0.96      0.98        26\n",
      "        12.0       0.94      1.00      0.97        17\n",
      "        13.0       0.85      0.85      0.85        20\n",
      "        14.0       0.95      0.95      0.95        21\n",
      "        15.0       0.94      1.00      0.97        16\n",
      "        16.0       1.00      1.00      1.00        22\n",
      "        17.0       1.00      1.00      1.00        22\n",
      "        18.0       1.00      1.00      1.00        25\n",
      "        19.0       1.00      1.00      1.00        23\n",
      "        20.0       1.00      0.94      0.97        18\n",
      "        21.0       1.00      0.94      0.97        18\n",
      "        22.0       0.82      0.75      0.78        24\n",
      "        23.0       0.96      0.69      0.80        32\n",
      "        24.0       0.79      0.71      0.75        21\n",
      "        25.0       0.94      0.94      0.94        18\n",
      "        26.0       1.00      1.00      1.00        22\n",
      "        27.0       0.96      0.92      0.94        24\n",
      "        28.0       0.79      0.96      0.87        24\n",
      "        29.0       0.94      0.94      0.94        16\n",
      "        30.0       0.91      1.00      0.95        20\n",
      "        31.0       0.88      0.83      0.86        18\n",
      "        32.0       0.73      0.84      0.78        19\n",
      "        33.0       0.95      1.00      0.98        20\n",
      "        34.0       1.00      0.96      0.98        26\n",
      "        35.0       0.87      0.91      0.89        22\n",
      "\n",
      "    accuracy                           0.91       755\n",
      "   macro avg       0.91      0.91      0.91       755\n",
      "weighted avg       0.91      0.91      0.91       755\n",
      "\n",
      "Accuracy: 90.86%\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d787c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 700\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a3521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.92      0.87        25\n",
      "         1.0       0.81      0.77      0.79        22\n",
      "         2.0       0.77      0.85      0.81        20\n",
      "         3.0       1.00      1.00      1.00        23\n",
      "         4.0       0.77      0.95      0.85        21\n",
      "         5.0       0.95      0.90      0.93        21\n",
      "         6.0       0.87      0.62      0.72        21\n",
      "         7.0       0.88      0.83      0.86        18\n",
      "         8.0       0.86      0.95      0.90        19\n",
      "         9.0       1.00      0.94      0.97        17\n",
      "        10.0       0.93      1.00      0.97        14\n",
      "        11.0       1.00      0.88      0.94        26\n",
      "        12.0       0.83      0.88      0.86        17\n",
      "        13.0       0.89      0.80      0.84        20\n",
      "        14.0       0.86      0.90      0.88        21\n",
      "        15.0       0.94      0.94      0.94        16\n",
      "        16.0       1.00      1.00      1.00        22\n",
      "        17.0       0.96      1.00      0.98        22\n",
      "        18.0       0.92      0.92      0.92        25\n",
      "        19.0       0.96      1.00      0.98        23\n",
      "        20.0       0.94      0.89      0.91        18\n",
      "        21.0       0.89      0.89      0.89        18\n",
      "        22.0       0.72      0.88      0.79        24\n",
      "        23.0       0.81      0.66      0.72        32\n",
      "        24.0       0.94      0.76      0.84        21\n",
      "        25.0       0.95      1.00      0.97        18\n",
      "        26.0       1.00      1.00      1.00        22\n",
      "        27.0       0.91      0.88      0.89        24\n",
      "        28.0       0.76      0.92      0.83        24\n",
      "        29.0       0.88      0.88      0.88        16\n",
      "        30.0       0.85      0.85      0.85        20\n",
      "        31.0       0.78      0.78      0.78        18\n",
      "        32.0       0.84      0.84      0.84        19\n",
      "        33.0       1.00      1.00      1.00        20\n",
      "        34.0       0.96      0.96      0.96        26\n",
      "        35.0       0.90      0.86      0.88        22\n",
      "\n",
      "    accuracy                           0.89       755\n",
      "   macro avg       0.89      0.89      0.89       755\n",
      "weighted avg       0.89      0.89      0.89       755\n",
      "\n",
      "Accuracy: 88.87%\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f9b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 1200\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b994eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.84      0.84        25\n",
      "         1.0       0.87      0.91      0.89        22\n",
      "         2.0       0.81      0.85      0.83        20\n",
      "         3.0       1.00      1.00      1.00        23\n",
      "         4.0       0.91      0.95      0.93        21\n",
      "         5.0       0.91      0.95      0.93        21\n",
      "         6.0       0.81      0.62      0.70        21\n",
      "         7.0       0.85      0.94      0.89        18\n",
      "         8.0       1.00      0.95      0.97        19\n",
      "         9.0       0.94      1.00      0.97        17\n",
      "        10.0       0.93      1.00      0.97        14\n",
      "        11.0       1.00      0.92      0.96        26\n",
      "        12.0       0.94      0.94      0.94        17\n",
      "        13.0       0.90      0.90      0.90        20\n",
      "        14.0       0.90      0.90      0.90        21\n",
      "        15.0       1.00      1.00      1.00        16\n",
      "        16.0       0.96      1.00      0.98        22\n",
      "        17.0       1.00      0.95      0.98        22\n",
      "        18.0       0.93      1.00      0.96        25\n",
      "        19.0       1.00      1.00      1.00        23\n",
      "        20.0       0.88      0.83      0.86        18\n",
      "        21.0       0.89      0.94      0.92        18\n",
      "        22.0       0.88      0.92      0.90        24\n",
      "        23.0       1.00      0.78      0.88        32\n",
      "        24.0       0.85      0.81      0.83        21\n",
      "        25.0       0.94      0.89      0.91        18\n",
      "        26.0       0.96      1.00      0.98        22\n",
      "        27.0       1.00      0.88      0.93        24\n",
      "        28.0       0.92      0.92      0.92        24\n",
      "        29.0       0.94      0.94      0.94        16\n",
      "        30.0       0.86      0.95      0.90        20\n",
      "        31.0       0.94      0.83      0.88        18\n",
      "        32.0       0.62      0.84      0.71        19\n",
      "        33.0       1.00      1.00      1.00        20\n",
      "        34.0       0.93      1.00      0.96        26\n",
      "        35.0       0.95      0.91      0.93        22\n",
      "\n",
      "    accuracy                           0.92       755\n",
      "   macro avg       0.92      0.92      0.92       755\n",
      "weighted avg       0.92      0.92      0.92       755\n",
      "\n",
      "Accuracy: 91.66%\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb02b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Step 1: Feature Extraction\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    # Check if descriptors is not None and has at least one row\n",
    "    if descriptors is not None and descriptors.shape[0] > 0:\n",
    "        return descriptors\n",
    "    else:\n",
    "        return np.zeros((1, 128), dtype=np.float32) # Return empty array of shape (0, 128)\n",
    "\n",
    "# Step 2: Feature Clustering\n",
    "def learn_visual_words(train_images, num_words):\n",
    "    # Concatenate features from all images\n",
    "    descriptors = np.concatenate([extract_features(img) for img in train_images])\n",
    "    # Cluster features into visual words\n",
    "    kmeans = KMeans(n_clusters=num_words, random_state=0).fit(descriptors.astype(np.float32))\n",
    "    return kmeans\n",
    "\n",
    "# Step 3: Feature Quantization\n",
    "def quantize_features(features, kmeans):\n",
    "    visual_words = kmeans.predict(features)\n",
    "    return visual_words.astype(np.int32)\n",
    "\n",
    "# Step 4: Histogram Creation\n",
    "def create_histogram(visual_words, num_words):\n",
    "    histogram = np.zeros(num_words, dtype=np.float32)\n",
    "    visual_words = visual_words.astype(np.int32)  # convert visual_words to int32\n",
    "    for word in visual_words:\n",
    "        histogram[word] += 1\n",
    "    return histogram\n",
    "\n",
    "# Step 5: Classifier Training and Testing\n",
    "def train_classifier(train_histograms, train_labels):\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(train_histograms.astype(np.float32), train_labels.astype(np.float32))\n",
    "    return svm\n",
    "\n",
    "def test_classifier(svm, test_histograms, test_labels):\n",
    "    pred_labels = svm.predict(test_histograms.astype(np.float32))\n",
    "    print(classification_report(test_labels.astype(np.float32), pred_labels.astype(np.float32)))\n",
    "    accuracy = accuracy_score(test_labels.astype(np.float32), pred_labels.astype(np.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Load train and test images\n",
    "train_images = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "test_images = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Learn visual words\n",
    "num_words = 1600\n",
    "kmeans = learn_visual_words(train_images, num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e6d287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.80      0.83        25\n",
      "         1.0       0.87      0.91      0.89        22\n",
      "         2.0       0.85      0.85      0.85        20\n",
      "         3.0       1.00      1.00      1.00        23\n",
      "         4.0       0.95      1.00      0.98        21\n",
      "         5.0       0.95      1.00      0.98        21\n",
      "         6.0       0.79      0.71      0.75        21\n",
      "         7.0       0.86      1.00      0.92        18\n",
      "         8.0       0.95      0.95      0.95        19\n",
      "         9.0       1.00      1.00      1.00        17\n",
      "        10.0       1.00      1.00      1.00        14\n",
      "        11.0       1.00      0.92      0.96        26\n",
      "        12.0       0.94      0.88      0.91        17\n",
      "        13.0       0.94      0.85      0.89        20\n",
      "        14.0       1.00      0.95      0.98        21\n",
      "        15.0       1.00      1.00      1.00        16\n",
      "        16.0       0.96      1.00      0.98        22\n",
      "        17.0       1.00      1.00      1.00        22\n",
      "        18.0       1.00      1.00      1.00        25\n",
      "        19.0       1.00      1.00      1.00        23\n",
      "        20.0       1.00      0.94      0.97        18\n",
      "        21.0       0.95      1.00      0.97        18\n",
      "        22.0       0.84      0.88      0.86        24\n",
      "        23.0       0.93      0.84      0.89        32\n",
      "        24.0       0.77      0.81      0.79        21\n",
      "        25.0       1.00      1.00      1.00        18\n",
      "        26.0       1.00      1.00      1.00        22\n",
      "        27.0       0.95      0.88      0.91        24\n",
      "        28.0       0.96      1.00      0.98        24\n",
      "        29.0       0.89      1.00      0.94        16\n",
      "        30.0       0.95      0.95      0.95        20\n",
      "        31.0       1.00      0.89      0.94        18\n",
      "        32.0       0.80      0.84      0.82        19\n",
      "        33.0       0.91      1.00      0.95        20\n",
      "        34.0       0.93      1.00      0.96        26\n",
      "        35.0       0.91      0.91      0.91        22\n",
      "\n",
      "    accuracy                           0.94       755\n",
      "   macro avg       0.94      0.94      0.94       755\n",
      "weighted avg       0.94      0.94      0.93       755\n",
      "\n",
      "Accuracy: 93.51%\n"
     ]
    }
   ],
   "source": [
    "# Compute histograms for train and test images\n",
    "train_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in train_images])\n",
    "test_histograms = np.array([create_histogram(quantize_features(extract_features(img), kmeans), num_words) for img in test_images])\n",
    "\n",
    "# Train and test SVM classifier\n",
    "svm = train_classifier(train_histograms, train_labels)\n",
    "accuracy = test_classifier(svm, test_histograms, test_labels)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04427a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
