{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36c50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from skimage.feature import canny\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729fc7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDGE BASED SEGMENTATION\n",
    "def preprocess1(image):\n",
    "  # resizing\n",
    "  image = cv2.resize(image,(96,96))\n",
    "  # gray scaling\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  # log transformation\n",
    "  c=0\n",
    "  if np.max(image) == 0:\n",
    "        c=0\n",
    "  else:\n",
    "        c = 255 / np.log(1 + np.max(image)) \n",
    "  log_image = c * (np.log(image + 1)) \n",
    "  log_image = np.array(log_image, dtype = np.uint8)  \n",
    "  # canny edge detection\n",
    "  image = canny(log_image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d4f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42160/383682156.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  log_image = c * (np.log(image + 1))\n"
     ]
    }
   ],
   "source": [
    "rootdir = 'asl_alphabet/asl_alphabet_train/asl_alphabet_train'\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for folder in os.listdir(rootdir):\n",
    "    classes = os.path.join(rootdir,folder)\n",
    "    label = folder\n",
    "    for file in os.listdir(classes):\n",
    "        img = os.path.join(classes, file)\n",
    "        image = cv2.imread(img)\n",
    "        image = preprocess1(image)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3de0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd10d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c77d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=80)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c828473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 20}\n",
      "Best score:  0.9566338259441707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       886\n",
      "           1       0.96      0.99      0.98       881\n",
      "           2       0.97      0.98      0.98       897\n",
      "           3       0.97      0.97      0.97       898\n",
      "           4       0.96      0.95      0.96       951\n",
      "           5       0.98      0.98      0.98       926\n",
      "           6       0.98      0.98      0.98       895\n",
      "           7       0.98      0.99      0.99       851\n",
      "           8       0.98      0.97      0.97       883\n",
      "           9       0.99      0.99      0.99       904\n",
      "          10       0.98      0.98      0.98       907\n",
      "          11       0.99      0.99      0.99       847\n",
      "          12       0.96      0.95      0.96       873\n",
      "          13       0.96      0.95      0.96       892\n",
      "          14       0.94      0.95      0.95       878\n",
      "          15       0.98      0.97      0.98       925\n",
      "          16       0.98      0.98      0.98       866\n",
      "          17       0.94      0.95      0.94       921\n",
      "          18       0.95      0.95      0.95       853\n",
      "          19       0.95      0.93      0.94       901\n",
      "          20       0.91      0.92      0.91       947\n",
      "          21       0.92      0.90      0.91       966\n",
      "          22       0.90      0.96      0.93       881\n",
      "          23       0.95      0.93      0.94       875\n",
      "          24       0.95      0.95      0.95       900\n",
      "          25       0.96      0.97      0.96       870\n",
      "          26       0.98      0.98      0.98       972\n",
      "          27       1.00      1.00      1.00       934\n",
      "          28       0.97      0.98      0.98       920\n",
      "\n",
      "    accuracy                           0.96     26100\n",
      "   macro avg       0.96      0.96      0.96     26100\n",
      "weighted avg       0.96      0.96      0.96     26100\n",
      "\n",
      "Accuracy: 96.31%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e87ee5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=80, accuracy=96\n",
    "# n=100, accuracy=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2d23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ed201ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=100)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "797eef1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'num_leaves': 20}\n",
      "Best score:  0.9570935960591133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       886\n",
      "           1       0.96      0.99      0.97       881\n",
      "           2       0.98      0.98      0.98       897\n",
      "           3       0.97      0.98      0.97       898\n",
      "           4       0.96      0.96      0.96       951\n",
      "           5       0.99      0.98      0.98       926\n",
      "           6       0.98      0.97      0.98       895\n",
      "           7       0.98      0.99      0.98       851\n",
      "           8       0.98      0.97      0.97       883\n",
      "           9       0.99      0.99      0.99       904\n",
      "          10       0.98      0.98      0.98       907\n",
      "          11       0.99      0.99      0.99       847\n",
      "          12       0.95      0.95      0.95       873\n",
      "          13       0.96      0.95      0.95       892\n",
      "          14       0.93      0.95      0.94       878\n",
      "          15       0.98      0.97      0.98       925\n",
      "          16       0.99      0.98      0.98       866\n",
      "          17       0.94      0.95      0.95       921\n",
      "          18       0.94      0.96      0.95       853\n",
      "          19       0.96      0.91      0.94       901\n",
      "          20       0.90      0.92      0.91       947\n",
      "          21       0.92      0.90      0.91       966\n",
      "          22       0.90      0.95      0.93       881\n",
      "          23       0.95      0.94      0.94       875\n",
      "          24       0.96      0.96      0.96       900\n",
      "          25       0.95      0.96      0.96       870\n",
      "          26       0.99      0.97      0.98       972\n",
      "          27       1.00      1.00      1.00       934\n",
      "          28       0.98      0.98      0.98       920\n",
      "\n",
      "    accuracy                           0.96     26100\n",
      "   macro avg       0.96      0.96      0.96     26100\n",
      "weighted avg       0.96      0.96      0.96     26100\n",
      "\n",
      "Accuracy: 96.30%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "239706c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c214923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=150)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8f726a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 20}\n",
      "Best score:  0.9570771756978654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       886\n",
      "           1       0.96      0.99      0.97       881\n",
      "           2       0.98      0.98      0.98       897\n",
      "           3       0.96      0.97      0.97       898\n",
      "           4       0.95      0.95      0.95       951\n",
      "           5       0.98      0.99      0.98       926\n",
      "           6       0.98      0.97      0.98       895\n",
      "           7       0.98      0.99      0.99       851\n",
      "           8       0.98      0.97      0.97       883\n",
      "           9       1.00      0.99      0.99       904\n",
      "          10       0.98      0.98      0.98       907\n",
      "          11       0.99      0.99      0.99       847\n",
      "          12       0.96      0.95      0.95       873\n",
      "          13       0.96      0.95      0.95       892\n",
      "          14       0.93      0.95      0.94       878\n",
      "          15       0.98      0.97      0.98       925\n",
      "          16       0.98      0.98      0.98       866\n",
      "          17       0.94      0.95      0.94       921\n",
      "          18       0.95      0.95      0.95       853\n",
      "          19       0.96      0.94      0.95       901\n",
      "          20       0.90      0.92      0.91       947\n",
      "          21       0.92      0.89      0.91       966\n",
      "          22       0.90      0.95      0.92       881\n",
      "          23       0.96      0.94      0.95       875\n",
      "          24       0.95      0.95      0.95       900\n",
      "          25       0.96      0.96      0.96       870\n",
      "          26       0.98      0.97      0.98       972\n",
      "          27       1.00      1.00      1.00       934\n",
      "          28       0.98      0.98      0.98       920\n",
      "\n",
      "    accuracy                           0.96     26100\n",
      "   macro avg       0.96      0.96      0.96     26100\n",
      "weighted avg       0.96      0.96      0.96     26100\n",
      "\n",
      "Accuracy: 96.26%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7a78686",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a1c3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=180)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14835618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 20}\n",
      "Best score:  0.9558128078817735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       886\n",
      "           1       0.97      0.99      0.98       881\n",
      "           2       0.98      0.99      0.98       897\n",
      "           3       0.96      0.97      0.97       898\n",
      "           4       0.97      0.94      0.95       951\n",
      "           5       0.98      0.99      0.99       926\n",
      "           6       0.98      0.97      0.97       895\n",
      "           7       0.98      0.98      0.98       851\n",
      "           8       0.97      0.97      0.97       883\n",
      "           9       0.99      0.99      0.99       904\n",
      "          10       0.98      0.97      0.97       907\n",
      "          11       0.99      0.99      0.99       847\n",
      "          12       0.96      0.94      0.95       873\n",
      "          13       0.95      0.95      0.95       892\n",
      "          14       0.94      0.95      0.94       878\n",
      "          15       0.98      0.97      0.98       925\n",
      "          16       0.98      0.98      0.98       866\n",
      "          17       0.94      0.95      0.95       921\n",
      "          18       0.95      0.95      0.95       853\n",
      "          19       0.96      0.93      0.94       901\n",
      "          20       0.90      0.91      0.91       947\n",
      "          21       0.93      0.89      0.91       966\n",
      "          22       0.90      0.96      0.93       881\n",
      "          23       0.95      0.94      0.95       875\n",
      "          24       0.95      0.96      0.96       900\n",
      "          25       0.97      0.97      0.97       870\n",
      "          26       0.98      0.98      0.98       972\n",
      "          27       1.00      1.00      1.00       934\n",
      "          28       0.98      0.98      0.98       920\n",
      "\n",
      "    accuracy                           0.96     26100\n",
      "   macro avg       0.96      0.96      0.96     26100\n",
      "weighted avg       0.96      0.96      0.96     26100\n",
      "\n",
      "Accuracy: 96.26%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9cf1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6e655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=200)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1fa859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 20}\n",
      "Best score:  0.9564696223316913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       886\n",
      "           1       0.96      0.99      0.97       881\n",
      "           2       0.98      0.98      0.98       897\n",
      "           3       0.96      0.97      0.96       898\n",
      "           4       0.95      0.94      0.94       951\n",
      "           5       0.98      0.98      0.98       926\n",
      "           6       0.98      0.97      0.97       895\n",
      "           7       0.98      0.98      0.98       851\n",
      "           8       0.98      0.96      0.97       883\n",
      "           9       0.99      0.99      0.99       904\n",
      "          10       0.98      0.98      0.98       907\n",
      "          11       0.98      0.99      0.99       847\n",
      "          12       0.96      0.95      0.95       873\n",
      "          13       0.96      0.96      0.96       892\n",
      "          14       0.93      0.94      0.94       878\n",
      "          15       0.98      0.97      0.98       925\n",
      "          16       0.98      0.98      0.98       866\n",
      "          17       0.94      0.94      0.94       921\n",
      "          18       0.95      0.95      0.95       853\n",
      "          19       0.96      0.93      0.94       901\n",
      "          20       0.89      0.91      0.90       947\n",
      "          21       0.90      0.91      0.90       966\n",
      "          22       0.90      0.95      0.93       881\n",
      "          23       0.96      0.92      0.94       875\n",
      "          24       0.96      0.95      0.95       900\n",
      "          25       0.96      0.97      0.97       870\n",
      "          26       0.98      0.98      0.98       972\n",
      "          27       1.00      1.00      1.00       934\n",
      "          28       0.98      0.98      0.98       920\n",
      "\n",
      "    accuracy                           0.96     26100\n",
      "   macro avg       0.96      0.96      0.96     26100\n",
      "weighted avg       0.96      0.96      0.96     26100\n",
      "\n",
      "Accuracy: 96.06%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb3e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92ed638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=300)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a27718b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 20}\n",
      "Best score:  0.9536124794745484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       886\n",
      "           1       0.96      0.99      0.97       881\n",
      "           2       0.97      0.98      0.98       897\n",
      "           3       0.96      0.96      0.96       898\n",
      "           4       0.95      0.94      0.94       951\n",
      "           5       0.98      0.98      0.98       926\n",
      "           6       0.97      0.97      0.97       895\n",
      "           7       0.98      0.98      0.98       851\n",
      "           8       0.98      0.97      0.97       883\n",
      "           9       1.00      0.99      0.99       904\n",
      "          10       0.96      0.97      0.97       907\n",
      "          11       0.98      0.99      0.98       847\n",
      "          12       0.95      0.95      0.95       873\n",
      "          13       0.95      0.95      0.95       892\n",
      "          14       0.93      0.94      0.94       878\n",
      "          15       0.98      0.97      0.97       925\n",
      "          16       0.98      0.98      0.98       866\n",
      "          17       0.94      0.94      0.94       921\n",
      "          18       0.94      0.95      0.94       853\n",
      "          19       0.96      0.93      0.94       901\n",
      "          20       0.90      0.91      0.91       947\n",
      "          21       0.90      0.90      0.90       966\n",
      "          22       0.90      0.95      0.93       881\n",
      "          23       0.97      0.93      0.95       875\n",
      "          24       0.96      0.96      0.96       900\n",
      "          25       0.97      0.97      0.97       870\n",
      "          26       0.98      0.97      0.98       972\n",
      "          27       1.00      1.00      1.00       934\n",
      "          28       0.97      0.98      0.97       920\n",
      "\n",
      "    accuracy                           0.96     26100\n",
      "   macro avg       0.96      0.96      0.96     26100\n",
      "weighted avg       0.96      0.96      0.96     26100\n",
      "\n",
      "Accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ebc3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53c6a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_flat)\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=120)\n",
    "X = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667323d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 20}\n",
      "Best score:  0.9574384236453202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       886\n",
      "           1       0.96      0.99      0.98       881\n",
      "           2       0.98      0.98      0.98       897\n",
      "           3       0.97      0.97      0.97       898\n",
      "           4       0.96      0.95      0.95       951\n",
      "           5       0.98      0.99      0.99       926\n",
      "           6       0.98      0.98      0.98       895\n",
      "           7       0.98      0.98      0.98       851\n",
      "           8       0.98      0.98      0.98       883\n",
      "           9       0.99      0.99      0.99       904\n",
      "          10       0.98      0.98      0.98       907\n",
      "          11       0.99      0.99      0.99       847\n",
      "          12       0.96      0.95      0.95       873\n",
      "          13       0.96      0.96      0.96       892\n",
      "          14       0.94      0.95      0.94       878\n",
      "          15       0.98      0.98      0.98       925\n",
      "          16       0.99      0.99      0.99       866\n",
      "          17       0.95      0.95      0.95       921\n",
      "          18       0.95      0.95      0.95       853\n",
      "          19       0.96      0.93      0.94       901\n",
      "          20       0.90      0.92      0.91       947\n",
      "          21       0.91      0.90      0.91       966\n",
      "          22       0.92      0.95      0.93       881\n",
      "          23       0.95      0.93      0.94       875\n",
      "          24       0.96      0.95      0.95       900\n",
      "          25       0.96      0.95      0.96       870\n",
      "          26       0.98      0.97      0.98       972\n",
      "          27       1.00      1.00      1.00       934\n",
      "          28       0.98      0.99      0.98       920\n",
      "\n",
      "    accuracy                           0.96     26100\n",
      "   macro avg       0.96      0.96      0.96     26100\n",
      "weighted avg       0.96      0.96      0.96     26100\n",
      "\n",
      "Accuracy: 96.37%\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define LightGBM classifier and parameters to tune\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "params = {\n",
    "    'num_leaves': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find best parameters\n",
    "grid_search = GridSearchCV(lgb_clf, params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc186e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
